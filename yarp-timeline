#!/usr/bin/env python3

# yarp: yet another registry parser
# (c) Maxim Suhanov

from yarp import *
from yarp import __version__
import argparse
from collections import namedtuple
import os
import sys

PROGRAM_NAME = 'yarp-timeline'
PROGRAM_VERSION = __version__

Arguments = namedtuple('Arguments', [ 'primary_file', 'faster', 'remnant', 'truncated', 'jsonl' ])
TimelineEntry = namedtuple('TimelineEntry', [ 'path_or_name', 'is_deleted', 'is_path_known', 'timestamp' ])

def parse_args():
	"""Parse command line arguments and return a named tuple (Arguments)."""

	parser = argparse.ArgumentParser(prog = PROGRAM_NAME, description = 'Parse a Windows registry file, print the timeline for keys (including deleted ones).', add_help = False, prefix_chars = '-')

	group_main = parser.add_argument_group('Main arguments')
	group_opt = parser.add_argument_group('Optional arguments')
	group_misc = parser.add_argument_group('Miscellaneous arguments')

	group_main.add_argument('file', help = 'a registry file (primary) to parse')

	group_opt.add_argument('--fast', action = 'store_true', help = 'do not use intermediate states to extend the timeline when applying a transaction log (new format)')
	group_opt.add_argument('--remnant', action = 'store_true', help = 'include remnant data from transaction log files (new format)')
	group_opt.add_argument('--truncated', action = 'store_true', help = 'treat the registry file (primary) as truncated (this will also ignore transaction log files)')
	group_opt.add_argument('--jsonl', action = 'store_true', help = 'produce the JSONL output (one JSON value per line)')

	group_misc.add_argument('--help', action = 'help', help = 'show this help message and exit')
	group_misc.add_argument('--version', action = 'version', help = 'show the version number and exit', version = PROGRAM_VERSION)

	parsed_args = parser.parse_args()

	primary_file = parsed_args.file
	faster = parsed_args.fast
	remnant = parsed_args.remnant
	truncated = parsed_args.truncated
	jsonl = parsed_args.jsonl

	return Arguments(primary_file = primary_file, faster = faster, remnant = remnant, truncated = truncated, jsonl = jsonl)

keys_list = []
def extend_keys_list(do_deleted = False):
	def process_key(key):
		global keys_list

		key_parsed = parse_key(key, False)
		if key_parsed is not None:
			keys_list.append(key_parsed)

		for subkey in key.subkeys():
			try:
				process_key(subkey)
			except Registry.RegistryException:
				pass

	global hive

	process_key(hive.root_key())

	if do_deleted:
		global keys_list

		try:
			hive.walk_everywhere()
		except Registry.RegistryException:
			return

		scanner = RegistryRecover.Scanner(hive)
		for item in scanner.scan():
			if type(item) is Registry.RegistryKey:
				key_parsed = parse_key(item, True)
				if key_parsed is not None:
					keys_list.append(key_parsed)

def extend_keys_list_truncated():
	global hive
	global keys_list

	for item in hive.scan():
		if type(item) is Registry.RegistryKey:
			key_parsed = parse_key(item, False)
			if key_parsed is not None:
				keys_list.append(key_parsed)

	scanner = RegistryRecover.Scanner(hive, False)
	for item in scanner.scan():
		if type(item) is Registry.RegistryKey:
			key_parsed = parse_key(item, True)
			if key_parsed is not None:
				keys_list.append(key_parsed)

def process_remnant_data(log_files, recovery_result):
	def process_log_file(file_object, is_unused):
		try:
			log = RegistryFile.NewLogFile(file_object)
		except Registry.RegistryException:
			return 0

		global keys_list
		counter = 0

		sequence_numbers = log.list_remnant_log_entries(is_unused)
		for sequence_number in sequence_numbers:
			primary_file_rebuilt = log.rebuild_primary_file_using_remnant_log_entries(is_unused, sequence_number)
			counter += 1

			hive = Registry.RegistryHiveTruncated(primary_file_rebuilt)
			for item in hive.scan():
				if type(item) is Registry.RegistryKey:
					key_parsed = parse_key(item, False) # Treat this key as is (not as a deleted one).
					if key_parsed is not None:
						keys_list.append(key_parsed)

			scanner = RegistryRecover.Scanner(hive, False)
			for item in scanner.scan():
				if type(item) is Registry.RegistryKey:
					key_parsed = parse_key(item, True)
					if key_parsed is not None:
						keys_list.append(key_parsed)

			hive = None
			primary_file_rebuilt.close()

		return counter

	log_files_unused = []
	log_files_used = []

	if not recovery_result.recovered:
		for log_file in log_files:
			if log_file is None:
				continue

			log_files_unused.append(log_file)
	else:
		for log_file in log_files:
			if log_file is None:
				continue

			if log_file in recovery_result.file_objects:
				log_files_used.append(log_file)
			else:
				log_files_unused.append(log_file)

	counter = 0
	for log_file in log_files_unused:
		counter += process_log_file(log_file, True)

	for log_file in log_files_used:
		counter += process_log_file(log_file, False)

	print('Remnant log entries processed: {}'.format(counter), file = sys.stderr)

def parse_key(key, is_deleted):
	try:
		path_or_name = key.path()
	except Registry.RegistryException:
		path_or_name = key.name()
		is_path_known = False
	else:
		is_path_known = True

	try:
		timestamp = key.last_written_timestamp()
	except (ValueError, OverflowError):
		return

	return TimelineEntry(path_or_name = path_or_name, is_deleted = is_deleted, is_path_known = is_path_known, timestamp = timestamp)

def is_hive_obviously_truncated():
	global hive

	try:
		for subkey in hive.root_key().subkeys():
			pass
	except Registry.RegistryException:
		return True

	return False

def print_timeline_header():
	print('Registry file\tKey path/name\tIs deleted\tIs path known\tTimestamp (UTC)')

def print_timeline_entry(entry, registry_file):
	print('{}\t{}\t{}\t{}\t{}'.format(registry_file, entry.path_or_name, entry.is_deleted, entry.is_path_known, entry.timestamp))

def print_timeline(registry_file):
	global keys_list

	print_timeline_header()
	for entry in keys_list:
		print_timeline_entry(entry, registry_file)

def print_timeline_jsonl(registry_file):
	import json
	global keys_list

	for entry in keys_list:
		timestamp_str = entry.timestamp.isoformat()
		entry_dict = { 'registry_file': registry_file, 'key_path_or_name': entry.path_or_name, 'is_deleted': entry.is_deleted, 'is_path_known': entry.is_path_known, 'timestamp': timestamp_str }
		json_line = json.dumps(entry_dict)

		print(json_line)

args = parse_args()

if not os.path.isfile(args.primary_file):
	print('Primary file does not exist: {}'.format(args.primary_file), file = sys.stderr)
	sys.exit(255)

primary = open(args.primary_file, 'rb')

try:
	hive = Registry.RegistryHive(primary)
except RegistryFile.NotSupportedException:
	raise
except RegistryFile.BaseBlockException:
	print('File seems to be a fragment, converting it to a truncated primary file', file = sys.stderr)

	temp_obj = primary
	primary = RegistryFile.FragmentTranslator(temp_obj)
	temp_obj.close()

	is_truncated = True
except Registry.RegistryException:
	is_truncated = True
else:
	is_truncated = is_hive_obviously_truncated()

if is_truncated and not args.truncated:
	print('Primary file is truncated, use the "--truncated" switch', file = sys.stderr)
	sys.exit(1)

if args.truncated:
	hive = Registry.RegistryHiveTruncated(primary)
	extend_keys_list_truncated()

	keys_list = list(set(keys_list))
	keys_list.sort(key = lambda x: x.timestamp, reverse = True)

	if not args.jsonl:
		print_timeline(args.primary_file)
	else:
		print_timeline_jsonl(args.primary_file)

	hive = None
	primary.close()
	sys.exit(0)

extend_keys_list(True) # Extend the list of keys (including deleted ones) for the first time, before applying a transaction log.

log_files = RegistryHelpers.DiscoverLogFiles(args.primary_file)

log = None
if log_files.log_path is not None:
	log = open(log_files.log_path, 'rb')

log1 = None
if log_files.log1_path is not None:
	log1 = open(log_files.log1_path, 'rb')

log2 = None
if log_files.log2_path is not None:
	log2 = open(log_files.log2_path, 'rb')

if not args.faster:
	hive.log_entry_callback = extend_keys_list # Extend the list of keys (without deleted ones) each time a log entry has been applied.

try:
	recovery_result = hive.recover_auto(log, log1, log2)
except Registry.AutoRecoveryException:
	print('An error has occurred when recovering a hive using a transaction log', file = sys.stderr)
else:
	if recovery_result.recovered and not recovery_result.is_new_log:
		extend_keys_list() # Finally, extend the list of keys (without deleted ones) after an old transaction log file has been applied.
	elif recovery_result.recovered and recovery_result.is_new_log and args.faster:
		extend_keys_list()

	if args.remnant:
		process_remnant_data([log, log1, log2], recovery_result)

keys_list = list(set(keys_list))
keys_list.sort(key = lambda x: x.timestamp, reverse = True)

if not args.jsonl:
	print_timeline(args.primary_file)
else:
	print_timeline_jsonl(args.primary_file)

hive = None
primary.close()

if log is not None:
	log.close()

if log1 is not None:
	log1.close()

if log2 is not None:
	log2.close()
